{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SulemanShahani/Text-summarization-using-BERT-Latent-Semantic-Analysis-LSA-LexRank-and-T5-Transformers/blob/main/text_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from transformers import TFBartForConditionalGeneration, BartTokenizer\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "from string import punctuation\n",
        "import warnings\n",
        "import fitz  # PyMuPDF\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "from sumy.nlp.tokenizers import Tokenizer as SumyTokenizer\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
        "import nltk\n",
        "\n",
        "# Install PyMuPDF library\n",
        "!pip install PyMuPDF\n",
        "\n",
        "# Install sumy library\n",
        "!pip install sumy\n",
        "\n",
        "# Download nltk punkt tokenizer\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Filter out specific UserWarning messages\n",
        "warnings.filterwarnings(\"ignore\", message=\"All PyTorch model weights were used when initializing TFBartForConditionalGeneration.*\")\n",
        "\n",
        "# Initialize BART tokenizer with Byte-Pair Encoding (BPE)\n",
        "bart_tokenizer_bpe = BartTokenizer.from_pretrained('facebook/bart-large-cnn', tokenizer_type='BPE')\n",
        "\n",
        "# Load pre-trained BART model\n",
        "bart_model = TFBartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "\n",
        "# Load pre-trained T5 model and tokenizer\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "t5_tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "\n",
        "# Define function to read text from a PDF file\n",
        "def read_pdf(file_path):\n",
        "    \"\"\"\n",
        "    Read text from a PDF file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the PDF file.\n",
        "\n",
        "    Returns:\n",
        "        str: The text extracted from the PDF.\n",
        "    \"\"\"\n",
        "    text = \"\"\n",
        "    with fitz.open(file_path) as pdf_file:\n",
        "        for page_num in range(len(pdf_file)):\n",
        "            page = pdf_file.load_page(page_num)\n",
        "            text += page.get_text()\n",
        "    return text\n",
        "\n",
        "# Define text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = ''.join([c for c in text if c not in punctuation])\n",
        "    return text\n",
        "\n",
        "# Read text from a PDF file (You need to provide the file path)\n",
        "file_path = '/content/eng.pdf'\n",
        "text = read_pdf(file_path)\n",
        "\n",
        "# Text preprocessing for BART\n",
        "processed_text_bart = \"summarize \" + preprocess_text(text)\n",
        "\n",
        "# Tokenization using Byte-Pair Encoding (BPE) for BART\n",
        "input_ids_bart = bart_tokenizer_bpe.encode(processed_text_bart, return_tensors='tf', max_length=1024, truncation=True, add_special_tokens=True)\n",
        "\n",
        "# Generate the summary with BART\n",
        "summary_ids_bart = bart_model.generate(input_ids_bart, max_length=500)\n",
        "\n",
        "# Decode the summary for BART\n",
        "bart_summary = bart_tokenizer_bpe.decode(summary_ids_bart[0], skip_special_tokens=True)\n",
        "\n",
        "# Print BART Summary\n",
        "print(\"BART Summary:\")\n",
        "print(bart_summary)\n",
        "\n",
        "# Text preprocessing for T5\n",
        "processed_text_t5 = \"summarize \" + preprocess_text(text)\n",
        "\n",
        "# Encode the input text for T5\n",
        "input_ids_t5 = t5_tokenizer.encode(processed_text_t5, return_tensors='pt', max_length=2000, truncation=True, add_special_tokens=True)\n",
        "\n",
        "# Generate the summary with T5\n",
        "summary_ids_t5 = t5_model.generate(input_ids_t5, max_length=500)\n",
        "\n",
        "# Decode the summary for T5\n",
        "t5_summary = t5_tokenizer.decode(summary_ids_t5[0], skip_special_tokens=True)\n",
        "\n",
        "# Post-process T5 summary to proper case\n",
        "sentences = t5_summary.split('. ')\n",
        "proper_case_summary = '. '.join([sentence.capitalize() for sentence in sentences])\n",
        "\n",
        "# Print T5 Summary\n",
        "print(\"T5 Summary (Proper Case):\")\n",
        "print(proper_case_summary)\n",
        "\n",
        "# Text summarization using LSA\n",
        "text_to_summarize = text\n",
        "parser = PlaintextParser.from_string(text_to_summarize, SumyTokenizer('english'))\n",
        "lsa_summarizer = LsaSummarizer()\n",
        "lsa_summary = lsa_summarizer(parser.document, 25)\n",
        "\n",
        "# Print LSA Summary\n",
        "print(\"LSA Summary:\")\n",
        "for sentence_lsa in lsa_summary:\n",
        "    print(sentence_lsa)\n",
        "\n",
        "# Text summarization using LexRank\n",
        "lexrank_summarizer = LexRankSummarizer()\n",
        "lexrank_summary = lexrank_summarizer(parser.document, sentences_count=25)\n",
        "\n",
        "# Print LexRank Summary\n",
        "print(\"LexRank Summary:\")\n",
        "for sentence_lexrank in lexrank_summary:\n",
        "    print(sentence_lexrank)\n"
      ],
      "metadata": {
        "id": "4fcLjFl8iy56"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPf/Z/7ZXjZD1O0JTRS32U9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}